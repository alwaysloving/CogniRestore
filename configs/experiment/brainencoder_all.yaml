# @package _global_

# to execute this experiment run:
# python train.py experiment=example

### write tags in every serious experiment! ###

# if serious run: hydra=seriousrun.yaml

# if all subjects: -m data.subjects=[sub-01],[sub-02],[sub-03],[sub-04],[sub-05],[sub-06],[sub-07],[sub-08],[sub-09],[sub-10]

# train and test in different subjects:
# -m
# model.top_k=[1,3,5,7,10]
# model.top_k=15,20,25,30,50,100,200,500
# data.subjects=[sub-01,sub-02,sub-03,sub-04,sub-05,sub-06,sub-07,sub-08,sub-09,sub-10]
# data.exclude_subject=sub-01,sub-02,sub-03,sub-04,sub-05,sub-06,sub-07,sub-08,sub-09,sub-10 ## no this, no exclude subject


defaults:
  - override /data: null
  - override /model: null
  - override /callbacks: default
  - override /trainer: gpu
# all parameters below will be merged with parameters from default configurations set above
# this allows you to overwrite only specified parameters

tags: ["experiment batch=1024 img_index used All subjects"]

seed: 114514

train: True

trainer:
  min_epochs: 1
  max_epochs: 50
  # gradient_clip_val: 0.5 not working in manual optimization

model:
  _target_: src.models.Cogcap_allmodality_module.Cogcap_allmodalitymodule

  feature_path : ${data.feature_path}
  automatic_optimization : False
  loss_type: Original
  top_k: 7
  cos_batch: 256
  optimizer:
    _target_: torch.optim.AdamW
    _partial_: true
    lr: 3e-4
    weight_decay: 0.0

  scheduler:
    _target_: torch.optim.lr_scheduler.ReduceLROnPlateau
    _partial_: true
    mode: min
    factor: 0.1
    patience: 10

  eegnet_img:
    _target_: src.models.components.Cogcap.Cogcap.Cogcap
    num_subjects: 10
    num_latents: 1024
    sequence_length: 250

  eegnet_text:
    _target_: src.models.components.Cogcap.Cogcap.Cogcap
    num_subjects: 10
    num_latents: 1024
    sequence_length: 250

  eegnet_depth:
    _target_: src.models.components.Cogcap.Cogcap.Cogcap
    num_subjects: 10
    num_latents: 1024
    sequence_length: 250

  imgnet:
    _target_: src.models.components.Cogcap.Cogcap.Proj_img

  textnet:
    _target_: src.models.components.Cogcap.Cogcap.Proj_text
    
  depthnet:
    _target_: src.models.components.Cogcap.Cogcap.Proj_depth

  # compile model for faster training with pytorch 2.0
  compile: true

model_2: null

data:
  _target_: src.data.THINGSEEG_datamodule.EEGDataModule
  exclude_subject: null
  use_route: False
  ratio: 0.0
  EEGdata_path_250hz: /root/autodl-fs/Things_eeg/preprocessed_data_250hz
  EEGdata_path_100hz: /root/autodl-fs/Things_eeg/preprocessed_eeg_data_100hz
  image_datapath: /root/autodl-fs/CognitionCapturer
  feature_path: /root/autodl-fs/CognitionCapturer/model_pretrained/data_features/
  use_ori_feature: False # important: change this and code in Modelmodule class
  subjects: [sub-08]
  batch_size: 1024
  num_workers: 0
  pin_memory: True
  drop_last: False

logger:
  defaults:
    - tensorboard
    - csv

callbacks:
  defaults:
    - model_checkpoint
    - early_stopping
    - model_summary
    - rich_progress_bar
    - _self_

  model_checkpoint:
    dirpath: ${paths.output_dir}/checkpoints
    filename: "{epoch:03d}_{top200class_accuracy/all:.02f}"
    monitor: "top200class_accuracy/all"
    mode: "max"
    save_top_k: 3
    save_last: True
    auto_insert_metric_name: True

  early_stopping:
    monitor: "top200class_accuracy/all"
    patience: 20
    mode: "max"

  model_summary:
    max_depth: -1
